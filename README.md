ğŸ“° Fake-News Classification: Preprocessing & Embedding Pipeline

A complete NLP preprocessing and embedding generation framework for fake-news detection on social media. This project cleans noisy text data, removes stopwords, performs lemmatization, and generates high-quality semantic embeddings using SentenceTransformer (all-mpnet-base-v2).
The output embeddings are saved for downstream ML models such as SVM, Logistic Regression, and deep neural networks.

ğŸš€ Features

âœ” Custom text-cleaning pipeline
âœ” Large curated stopword list
âœ” Lemmatization using WordNet
âœ” Transformer-based embeddings (all-mpnet-base-v2)
âœ” Saves embeddings + class labels as .pkl
âœ” Fully reproducible workflow
âœ” Ready for classification experiments

ğŸ“ Dataset

The raw dataset (_74429.csv) contains:

Column	Description
news	Social media post text
label	Fake (0) or Real (1)
ğŸ§¹ Preprocessing Pipeline

Your preprocessing pipeline performs:

Special Character Removal

Lowercasing

Tokenization

Stopword Removal (custom large stopword list)

Lemmatization

Sentence Reconstruction

Mathematical representation:

ğ‘‡
ğ‘–
=
Lemmatize
(
RemoveStopwords
(
Lowercase
(
RemoveSpecialChars
(
ğ‘ 
ğ‘–
)
)
)
)
T
i
	â€‹

=Lemmatize(RemoveStopwords(Lowercase(RemoveSpecialChars(s
i
	â€‹

))))

A cleaned dataset is saved as:

_74429_V01.csv

ğŸ”¡ Sentence Embeddings

The cleaned text is encoded using:

Model
SentenceTransformer("all-mpnet-base-v2")

Embedding Equation
ğ¸
ğ‘–
=
ğ‘“
ğœƒ
(
ğ‘‡
ğ‘–
)
E
i
	â€‹

=f
Î¸
	â€‹

(T
i
	â€‹

)

Where:

ğ‘‡
ğ‘–
T
i
	â€‹

 = cleaned text

ğ¸
ğ‘–
E
i
	â€‹

 = embedding vector

ğ‘“
ğœƒ
f
Î¸
	â€‹

 = transformer model

Output Files

embeddings.pkl â€” all embedding vectors

embedding_classes.pkl â€” matching labels

ğŸ“¦ Installation
pip install pandas numpy nltk sentence-transformers tqdm


Download NLTK resources (first run only):

import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')

â–¶ï¸ Usage
1. Preprocess the dataset
from preprocess import cleanse
import pandas as pd

data = pd.read_csv("_74429.csv")

cleaned_df = pd.DataFrame({
    "news": data['news'].apply(cleanse),
    "class": data['label']
})

cleaned_df.to_csv("_74429_V01.csv", index=False)

2. Generate embeddings
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import pickle

model = SentenceTransformer("all-mpnet-base-v2")

embeddings = []
for text in tqdm(cleaned_df['news']):
    embeddings.append(model.encode(text))

with open("embeddings.pkl", "wb") as f:
    pickle.dump(embeddings, f)

with open("embedding_classes.pkl", "wb") as f:
    pickle.dump(list(cleaned_df['class']), f)

ğŸ“Š Next Steps / Future Work

Compare different embedding models (BGE, GTE, Gemini)

Fine-tune transformers on fake news datasets

Apply dimensionality reduction (PCA, UMAP)

Build downstream classifiers (SVM, CNN-BiLSTM, Transformers)

ğŸ“œ Citation

If you use this pipeline, consider citing:

Viswakarma Pidishetti, Rohit.  
"A Preprocessing and Embedding Framework for Social Media Fake-News Classification."

â­ Contribute

Contributions are welcome!
Feel free to open an issue or submit a pull request.
